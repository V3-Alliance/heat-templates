# Juno Release

# This template supports the use case of an application launched in the
# NeCTAR Research Cloud that needs a distributed file system that can be mounted
# as a POSIX mount in a *nix file stem.

# This configuration does not setup SSL, so client mounts
# outside a tenancy do not use encrypted communications.
# Remote clients are not able to mount the Gluster volume.
# "Connection refused" issues related to NeCTAR firewall rules maybe??

# This template sets up Cinder block storage to be used by the GlusterFS.

heat_template_version: 2014-10-16

description: >
  Template to create a SERVER cluster that provides a Gluster distributed file system.
  The distributed storage is located on Cinder volumes, with each volume attached to a 
  Nova server instance.

parameters:

    key_name:
        type: string
        label: Key Name
        description:
            Name of an existing key pair registered with OpenStack to enable SSH access to the instance.
        default: "my_nectar_key"
      
    # Might not be much point in using larger instance types
    # as we really just want the input/output to the block storage.      
    instance_type:
        type: string
        label: Instance Type
        description: Type of the instance (flavor) to be created.
        default: "m1.small"
        constraints:
            - allowed_values: [ m1.small, m1.medium, m1.large, m1.xlarge ]
              description: Value must be one of m1.small, m1.medium, m1.large or m1.xlarge.
    
    availability_zone:
        type: string
        label: Availability Zone
        description: The NeCTAR zone in which the VM is to run (must have block storage). 
        default: melbourne-np
        constraints:
            - allowed_values: [ melbourne-qh2, melbourne-np, monash, qld ]
              description: Value must be one of melbourne-qh2, melbourne-np, monash, qld.
    
    image_id:
        type: string
        label: Virtual Machine Image
        description: Base virtual machine image to be used to build compute instance.
        default: ubuntu-12.04
        constraints:
            - allowed_values: [ ubuntu-12.04, ubuntu-14.04, ubuntu-14.10 ]
              description: Value must be one of ubuntu-12.04, ubuntu-14.04, ubuntu-14.10.

    volume_size:
        type: number
        label: Volume Size / GB
        description: Size of the persistent volume to be created in Gigabytes.
        default: 1
        constraints:
            - range: { min: 1, max: 1024 }
              description: must be between 1 GB and 1024 GB (1 TB).
    
    # We will limit the maximum number of server instances in the cluster to 10. Just because.
    instance_count:
        type: number
        label: Cluster Size
        description: "The number of server instances (nodes) created to make up the cluster. "
        default: 2
        constraints:
            - range: { min: 1, max: 10 }
              description: "Value must be between 1 and 10. "


resources:

    cluster_security_group:
        type: "AWS::EC2::SecurityGroup"
        properties:
            GroupDescription: "Enable access between the machines in the Gluster cluster."
            SecurityGroupIngress:
            
                -   # Testing
                    IpProtocol: "icmp"
                    FromPort: "-1"
                    ToPort: "-1"
                    CidrIp: "0.0.0.0/0"
                    
                -   # Admin access
                    IpProtocol: "tcp"
                    FromPort: "22"
                    ToPort: "22"
                    CidrIp: "0.0.0.0/0"
                    
                -   # Portmapper
                    IpProtocol: "tcp"
                    FromPort: "111"
                    ToPort: "111"
                    CidrIp: "0.0.0.0/0"
                    
                -   # Portmapper
                    IpProtocol: "udp"
                    FromPort: "111"
                    ToPort: "111"
                    CidrIp: "0.0.0.0/0"
                    
                -   # Portmapper
                    IpProtocol: "tcp"
                    FromPort: "2049"
                    ToPort: "2049"
                    CidrIp: "0.0.0.0/0"
                    
                -   # Gluster daemon and management - 24007
                    # Infiniband management - 24008
                    IpProtocol: "tcp"
                    FromPort: "24007"
                    ToPort: "24008"
                    CidrIp: "0.0.0.0/0"
                    
                -   # Gluster version < 3.4 = number of bricks (10), adjust as necessary.
                    IpProtocol: "tcp"
                    FromPort: "24009"
                    ToPort: "24018"
                    CidrIp: "0.0.0.0/0"
                    
                -   # Gluster version >= 3.4 = number of bricks (10), adjust as necessary
                    IpProtocol: "tcp"
                    FromPort: "49152"
                    ToPort: "49161"
                    CidrIp: "0.0.0.0/0"
                    
                -    # NFS 3 ports
                    IpProtocol: "tcp"
                    FromPort: "38465"
                    ToPort: "38467"
                    CidrIp: "0.0.0.0/0"

    # Each slave is a VM and an attached Cinder volume
    slave_group:
        # http://docs.openstack.org/hot-reference/content/OS__Heat__ResourceGroup.html
        type: "OS::Heat::ResourceGroup"
        properties:
            count: { get_param: instance_count }
            resource_def: 
                type: gluster_slave_with_cinder_volume.yaml
                properties:
                    key_name: { get_param: key_name }
                    image_id: { get_param: image_id }
                    instance_type: { get_param: instance_type }
                    availability_zone: { get_param: availability_zone }
                    volume_size: { get_param:  volume_size }
                    security_group: { get_resource:  cluster_security_group }
                    group_index: "%index%"

    # The master is a VM and an attached Cinder volume
    master_group:
        # http://docs.openstack.org/hot-reference/content/OS__Heat__ResourceGroup.html
        type: "OS::Heat::ResourceGroup"
        depends_on: slave_group
        properties:
            count: 1
            resource_def: 
                type: gluster_master_with_cinder_volume.yaml
                properties:
                    key_name: { get_param: key_name }
                    image_id: { get_param: image_id }
                    instance_type: { get_param: instance_type }
                    availability_zone: { get_param: availability_zone }
                    volume_size: { get_param:  volume_size }
                    security_group: { get_resource:  cluster_security_group }
                    #slave_ips: { get_attr: [slave_group, instance_ips] }
                    slave_ips: "0.0.0.0"

outputs:
    "Master attributes": 
        value: { get_attr: [master_group, first_address] }
        description: "The IP number for the Gluster master server, so the admin can manage the master..."
    "Slave attributes": 
        value: {list_join: [',', { get_attr: [slave_group, first_address] }]}
        description: "The IP numbers for the Gluster slave servers, so the admin can manage the slaves..."
    "Slave attributes 2": 
        value: { get_attr: [slave_group, instance_ips] }
        description: "The IP numbers for the Gluster slave servers, so the admin can manage the slaves..."
    "End user instructions":
        description: "The command executed by the end user to mount the Gluster file system on some other machine..."
        value: 
            list_join: ['', ['sudo mkdir -p /mnt/glusterVol && sudo mount -t glusterfs ', get_attr: [master_group, first_address], ':gvl-volume /mnt/glusterVol']]
