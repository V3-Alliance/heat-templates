# Juno Release

# This template supports the use case of an application launched in the
# NeCTAR Research Cloud that needs a distributed file system that can be mounted
# as a POSIX mount in a *nix file stem.

# This configuration does not setup SSL, so client mounts
# outside a tenancy do not use encrypted communications.
# Remote clients are not able to mount the Gluster volume.
# "Connection refused" issues related to NeCTAR firewall rules maybe??

# This template sets up a single Gluster master node that uses Cinder block storage.
# This template is not intended to be used standalone, its included by the glusterfs template
# called glusterfs_on_cinder_volumes.yaml

heat_template_version: 2014-10-16

parameters:

    key_name:
        type: string
        label: Key Name
        description:
            Name of an existing key pair registered with OpenStack to enable SSH access to the instance.
        default: "my_nectar_key"
    
    image_id:
        type: string
        label: Virtual Machine Image
        description: Base virtual machine image to be used to build compute instance.
        default: ubuntu-12.04
        constraints:
            - allowed_values: [ ubuntu-12.04, ubuntu-14.04, ubuntu-14.10 ]
              description: Value must be one of ubuntu-12.04, ubuntu-14.04, ubuntu-14.10.
      
    # Might not be much point in using larger instance types
    # as we really just want the input/output to the block storage.      
    instance_type:
        type: string
        label: Instance Type
        description: Type of the instance (flavor) to be created.
        default: "m1.small"
        constraints:
            - allowed_values: [ m1.small, m1.medium, m1.large, m1.xlarge ]
              description: Value must be one of m1.small, m1.medium, m1.large or m1.xlarge.
    
    availability_zone:
        type: string
        label: Availability Zone
        description: The NeCTAR zone in which the VM is to run (must have block storage). 
        default: melbourne-np
        constraints:
            - allowed_values: [ melbourne-qh2, melbourne-np, monash, qld ]
              description: Value must be one of melbourne-qh2, melbourne-np, monash, qld.

    volume_size:
        type: number
        label: Volume Size / GB
        description: Size of the persistent volume to be created in Gigabytes.
        default: 1
        constraints:
            - range: { min: 1, max: 1024 }
              description: must be between 1 and 1024 Gb.
              
    security_group:
        type: string
        description: Security group used for cluster node and volume.
              
    slave_ips:
        type: string
        description: Slave ip addresses as comma-separated list.

resources:

    cluster_master:
        type: OS::Nova::Server
        properties:
            name: Gluster master
            key_name: { get_param: key_name }
            image: 
                "Fn::Select":
                    - { get_param: image_id }
                    -     
                        "ubuntu-12.04": "c395c528-fb43-4066-9536-cf5c5efe806d"
                        "ubuntu-14.04": "eeedf697-5a41-4d91-a478-01bb21e32cbe"
                        "ubuntu-14.10": "fc48b5bb-e67d-4e39-b9ba-b6725c8b0c88"
            flavor: { get_param: instance_type }
            availability_zone: {get_param: availability_zone}
            security_groups: [ { get_param: security_group } ]
            user_data_format: RAW
            user_data:
                str_replace:
                    template: |
                        #!/bin/bash
                        echo ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>"
                        echo "Begin: run user_data bash script. "
                        ############# Begin: common
                        apt-get -y install PROPERTIES_PACKAGE
                        add-apt-repository ppa:gluster/glusterfs-3.6
                        apt-get update
                        apt-get -y upgrade
                        apt-get install -y  --force-yes glusterfs-server
                        apt-get install -y  xfsprogs
                        # get rid of annoying message shown when running sudo command
                        echo "127.0.0.1     `hostname`" | tee -a /etc/hosts
                        # Only need to umount if we really want to mount the new storage under /mnt
                        # By leaving it alone we retain the secondary ephemeral storage.
                        umount /mnt
                        # Mount Cinder persistent local storage.
                        mkfs.xfs -f -i size=512 LOCAL_DEVICE
                        mkdir -p GLUSTER_STORAGE_DIRECTORY
                        mount LOCAL_DEVICE GLUSTER_STORAGE_DIRECTORY
                        # Make a place to store the Gluster bricks
                        mkdir -p GLUSTER_STORAGE_DIRECTORY/brick
                        # Remount on boot.
                        cp /etc/fstab /etc/fstab.bak
                        echo "LOCAL_DEVICE        GLUSTER_STORAGE_DIRECTORY    xfs    defaults 0       0"  >> /etc/fstab
                        echo "Mount directory: GLUSTER_STORAGE_DIRECTORY"
                        ############# End: common
                        # Create the slaves
                        SLAVE_IPS="SLAVE_IP_ADDRESS_LIST"
#                        echo "Instance IP addresses: $SLAVE_IPS"
#                        IFS=","
#                        MAX_PROBES=20
#                        PROBES=1
#                        for INSTANCE in $SLAVE_IPS; do
#                            # assumption is that gluster peer probe will return error code if peer isn't set up yet.
#                            until gluster peer probe $INSTANCE; do 
#                                echo "Probe failed : $?"; 
#                                if ["$PROBES" -gt "$MAX_PROBES" ]; then
#                                    echo "Slave probe timeout. "
#                                    exit 1
#                                fi
#                                PROBES=$((PROBES+1))
#                                sleep 5; 
#                            done
#                            # now wait for a while as we only want to proceed once the peer is up to speed...
#                            sleep 20
#                        done
#                        COMMAND_TAIL=""
#                        COUNTER=0
#                        for INSTANCE in $SLAVE_IPS; do
#                            COMMAND_TAIL+=" $INSTANCE:GLUSTER_STORAGE_DIRECTORY/brick"
#                            COUNTER=$((COUNTER+1))
#                        done
#                        # Add this machine's IP address to the volume create command.
#                        IP=`ifconfig  | grep 'inet addr:'| grep -v '127.0.0.1' | cut -d: -f2 | awk '{ print $1}'`;
#                        COMMAND_TAIL+=" $IP:GLUSTER_STORAGE_DIRECTORY/brick"
#                        COUNTER=$((COUNTER+1))
#                        echo "Gluster replication: $COUNTER"
#                        COMMAND="gluster volume create gvl-volume replica $COUNTER transport tcp $COMMAND_TAIL force"
#                        echo "Create using: $COMMAND"
#                        eval $COMMAND
#                        gluster volume start gvl-volume
#                        echo "End: run user_data bash script. "
#                        echo "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<"
                    params:
                        PROPERTIES_PACKAGE: 
                            "Fn::Select":
                                - { get_param: image_id }
                                -     
                                    "ubuntu-12.04": "python-software-properties"
                                    "ubuntu-14.04": "software-properties-common"
                                    "ubuntu-14.10": "software-properties-common"
                        GLUSTER_STORAGE_DIRECTORY: "/data/glusterfs/volume1"
                        LOCAL_DEVICE: /dev/vdc
                        # Recommended but does not work as GUID needs to be truncated to 20 characters.
                        #LOCAL_DEVICE: {list_join: ['', ['/dev/disk/by-id/virtio-', get_resource: cluster_master_volume ]]}     
                        SLAVE_IP_ADDRESS_LIST: { get_param: slave_ips }


    # http://docs.openstack.org/developer/heat/template_guide/openstack.html#OS::Cinder::Volume
    cluster_master_volume:
        type: OS::Cinder::Volume
        properties:
            name: Gluster server local storage
            description: "Local persistent storage volume for cluster master. "
            size: { get_param: volume_size }
            availability_zone: {get_param: availability_zone}
            
    # http://docs.openstack.org/developer/heat/template_guide/openstack.html#OS::Cinder::VolumeAttachment
    cluster_master_volume_attachment:
        type: OS::Cinder::VolumeAttachment      
        properties:
            volume_id: { get_resource: cluster_master_volume }
            instance_uuid: { get_resource: cluster_master }
            mountpoint: 
                /dev/vdc
                # Recommended, but does not work as ID needs to be truncated to 20 characters.
                #list_join: ['', ['/dev/disk/by-id/virtio-', get_resource: cluster_master_volume ]]
